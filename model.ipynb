{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0325d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a843b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision -f https://download.pytorch.org/whl/cu102/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff7b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642389b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=pd.read_csv('masked_nike.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c259feb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>target_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Mask] comfort [Mask] quality doubt weather fa...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought buying new shoe supposedly new shoe gu...</td>\n",
       "      <td>near</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really [Mask] product nike comfortable wear lo...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comfortable shoe wearwhich made good quality l...</td>\n",
       "      <td>attracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pleae dont buy neither looks like nike shoes  ...</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>earlier [Mask] serveral orders nikestoredk web...</td>\n",
       "      <td>placed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>couldnt believe somebody designed trainers ord...</td>\n",
       "      <td>accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>[Mask]ed items unfortunately fit nike gave ful...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>recieved fantastic pair [Mask]  brand</td>\n",
       "      <td>trainers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>site bomb quite often find things [Mask] buy s...</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           masked_text target_word\n",
       "0    [Mask] comfort [Mask] quality doubt weather fa...        good\n",
       "1    thought buying new shoe supposedly new shoe gu...        near\n",
       "2    really [Mask] product nike comfortable wear lo...        good\n",
       "3    comfortable shoe wearwhich made good quality l...    attracts\n",
       "4    pleae dont buy neither looks like nike shoes  ...       cheap\n",
       "..                                                 ...         ...\n",
       "806  earlier [Mask] serveral orders nikestoredk web...      placed\n",
       "807  couldnt believe somebody designed trainers ord...    accepted\n",
       "808  [Mask]ed items unfortunately fit nike gave ful...       order\n",
       "809              recieved fantastic pair [Mask]  brand    trainers\n",
       "810  site bomb quite often find things [Mask] buy s...        want\n",
       "\n",
       "[811 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecf4a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_length(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df_m['text_length'] = df_m['masked_text'].apply(get_text_length)\n",
    "df_m = df_m[df_m['text_length'] <= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900cf053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>target_word</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [masked_text, target_word, text_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m[df_m['text_length'] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a294d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c426e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=df_m[['masked_text','target_word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5211d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>target_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Mask] comfort [Mask] quality doubt weather fa...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought buying new shoe supposedly new shoe gu...</td>\n",
       "      <td>near</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really [Mask] product nike comfortable wear lo...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comfortable shoe wearwhich made good quality l...</td>\n",
       "      <td>attracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pleae dont buy neither looks like nike shoes  ...</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         masked_text target_word\n",
       "0  [Mask] comfort [Mask] quality doubt weather fa...        good\n",
       "1  thought buying new shoe supposedly new shoe gu...        near\n",
       "2  really [Mask] product nike comfortable wear lo...        good\n",
       "3  comfortable shoe wearwhich made good quality l...    attracts\n",
       "4  pleae dont buy neither looks like nike shoes  ...       cheap"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea157b",
   "metadata": {},
   "source": [
    "# BUILD MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d9841",
   "metadata": {},
   "source": [
    "step for building model\n",
    "1. Preprocess our text data: Convert the text into a format suitable for fine-tuning, such as converting all text to lowercase, removing stop words/depends on use case, punctuation and special characters, etc.\n",
    "\n",
    "2. Mask the text: Replace a word in the text with the [Mask] placeholder to create a masked sequence. we can choose to mask a random word in each sequence or mask a specific word based on your task.\n",
    "\n",
    "3. Create the target column: Create a target column that contains the masked word from the text column.\n",
    "\n",
    "4. Convert the data into a format suitable for fine-tuning: Convert the text and target columns into numerical data suitable for fine-tuning the model.\n",
    "\n",
    "5. Split the data into train, validation, and test sets: Split the preprocessed and converted data into three sets: training, validation, and testing.\n",
    "\n",
    "6. Load the distilbert-based-uncased model: Load the pre-trained distilbert-based-uncased model from the transformers library.\n",
    "\n",
    "7. Fine-tune the model: Train the model on the training data and use the validation data to adjust the model parameters for optimal performance.\n",
    "\n",
    "8. Evaluate the model: Use the test data to evaluate the model's performance and make any necessary adjustments.\n",
    "\n",
    "9. Save the fine-tuned model: Save the fine-tuned model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d763d709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_text</th>\n",
       "      <th>target_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Mask] comfort [Mask] quality doubt weather fa...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought buying new shoe supposedly new shoe gu...</td>\n",
       "      <td>near</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really [Mask] product nike comfortable wear lo...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comfortable shoe wearwhich made good quality l...</td>\n",
       "      <td>attracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pleae dont buy neither looks like nike shoes  ...</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>ordered [Mask] pair shoes heartrate monitor\\re...</td>\n",
       "      <td>gpsclock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>headaches return products online although comp...</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>couldnt believe somebody designed trainers ord...</td>\n",
       "      <td>accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>recieved fantastic pair [Mask]  brand</td>\n",
       "      <td>trainers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>site bomb quite often find things [Mask] buy s...</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           masked_text target_word\n",
       "0    [Mask] comfort [Mask] quality doubt weather fa...        good\n",
       "1    thought buying new shoe supposedly new shoe gu...        near\n",
       "2    really [Mask] product nike comfortable wear lo...        good\n",
       "3    comfortable shoe wearwhich made good quality l...    attracts\n",
       "4    pleae dont buy neither looks like nike shoes  ...       cheap\n",
       "..                                                 ...         ...\n",
       "742  ordered [Mask] pair shoes heartrate monitor\\re...    gpsclock\n",
       "743  headaches return products online although comp...   marketing\n",
       "744  couldnt believe somebody designed trainers ord...    accepted\n",
       "745              recieved fantastic pair [Mask]  brand    trainers\n",
       "746  site bomb quite often find things [Mask] buy s...        want\n",
       "\n",
       "[747 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290489d",
   "metadata": {},
   "source": [
    "# LOAD PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5742ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1 ,step2 and step3 is already \n",
    "#step4\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a212ed",
   "metadata": {},
   "source": [
    "# CREATE INPUT DATA(TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6e365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text and target columns into numerical data\n",
    "encoded_texts = [tokenizer.encode(text, add_special_tokens=True) for text in df_m['masked_text']]\n",
    "encoded_targets = [tokenizer.encode(target, add_special_tokens=True) for target in df_m['target_word']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198cb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_texts = [text[:70] for text in encoded_texts]#ONLY COLLECTING THEIR MAXIMUM LENGTH\n",
    "encoded_targets=[text[:70] for text in encoded_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b89b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the encoded data to the same length\n",
    "max_len = max(len(text) for text in encoded_texts)\n",
    "padded_texts = [text + [tokenizer.pad_token_id] * (max_len - len(text)) for text in encoded_texts]\n",
    "padded_targets = [target + [tokenizer.pad_token_id] * (max_len - len(target)) for target in encoded_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5db53d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e145b",
   "metadata": {},
   "source": [
    "# SPLITTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6668be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_texts, test_texts, train_targets, test_targets = train_test_split(padded_texts, padded_targets, test_size=0.2, random_state=42)\n",
    "train_texts, val_texts, train_targets, val_targets = train_test_split(train_texts, train_targets, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6619c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertForMaskedLM, DistilBertTokenizer\n",
    "# Load the DistilBERT model\n",
    "model = DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6253973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#model = model.to('cuda') # move the model to GPU if you have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd1e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input data into tensors\n",
    "train_texts = torch.tensor(train_texts)\n",
    "train_targets = torch.tensor(train_targets)\n",
    "test_texts = torch.tensor(test_texts)\n",
    "test_targets = torch.tensor(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e25939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForMaskedLM(\n",
       "  (activation): GELUActivation()\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (vocab_projector): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  (mlm_loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a008f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:<512>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98a1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "logits = model(train_texts, attention_mask=train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b7502b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits[0]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4550dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2413fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [10, 30522], got [10, 69]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [10, 30522], got [10, 69]"
     ]
    }
   ],
   "source": [
    "loss = criterion(logits[0][0:10], train_targets[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91322b9d",
   "metadata": {},
   "source": [
    "***\n",
    " a cross-entropy loss function is defined using the torch.nn.CrossEntropyLoss class.\n",
    " The forward pass is performed using the model object, and the result is stored in the logits variable. \n",
    " The loss is then computed by passing the logits and the ground-truth labels (train_targets) to the criterion object.\n",
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca90332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the loss and optimize the model parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
